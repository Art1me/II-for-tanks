# II-for-tanks
# -*- coding: utf-8 -*-
"""Копия блокнота "-matvey-tanks-ipynb.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j2QbxOr8mTHnReCtxJH6iOWuREnR80-5
"""

!python --version

import tensorflow as tf
tf.__version__

import keras
keras.__version__

import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib

"""# ПОДКЛЮЧЕНИЕ БИБЛИОТЕК И ЗАГРУЗКА БАЗЫ"""

import time

class my_timer():
  def __enter__(self):
    self.t = time.time()
    return self
  def __exit__(self,type,value,backtrace):
    print(round(time.time()-self.t, 2), ' сек.')

# Для подготовки файлов
import matplotlib.pyplot as plt
import random
from PIL import Image
import gdown
import os
# Для обучения нейросети
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization
from keras.optimizers import Adam, RMSprop,SGD,Adagrad,Adamax,Nadam
from keras.models import load_model
#from keras.utils.vis_utils import plot_model
from tensorflow.keras.utils import plot_model

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import tensorflow as tf

with my_timer():
  gdown.download('https://storage.yandexcloud.net/wot/RealTanks_norm.zip', None, quiet=True)

!unzip -qo RealTanks_norm.zip

!rm -rf TEST
!rm -rf TRAIN
# ПАРАМЕТРЫ
WOT_PATH = '/content/content/RealTanks_norm'
TRAIN_PATH = '/content/TRAIN'
TEST_PATH = '/content/TEST'

TEST_SPLIT = 0.15
TRAIN_SPLIT = 0.8

IMG_WIDTH = 405
IMG_HEIGHT = 360
IMG_CHANNELS = 3

List = os.listdir(WOT_PATH)
dict_ = {}
for len_tanks in List:
  path = len([name for name in os.listdir('/content/content/RealTanks_norm/' + len_tanks) if os.path.isfile(os.path.join('/content/content/RealTanks_norm/' + len_tanks,name))])
  dict_[len_tanks] = path
sns.barplot(x=dict_.keys(), y=dict_.values(), data = dict_ );
plt.xticks(rotation=45, ha='right');

os.listdir(WOT_PATH)

CLASS_LIST = sorted(os.listdir(WOT_PATH))
CLASS_COUNT = len(CLASS_LIST)
print('Количество танков: ',CLASS_COUNT, CLASS_LIST)

"""# Перенос файлов"""

# ПЕРЕНОС ФАЙЛОВ для EBR-105

#wrong_path = f'/content/WOT/EBR-105/EBR-105-images'
#to_wot_path = f'{WOT_PATH}/{CLASS_LIST[1]}'
#wrong_wot_files = os.listdir(wrong_path)
#wot_file_count = len(wrong_wot_files)

#for f in wrong_wot_files:
 #   os.rename(f'{wrong_path}/{f}', f'{to_wot_path}/{f}')№

#!rm -rf /content/WOT/EBR-105/EBR-105-images

os.mkdir(TEST_PATH)
os.mkdir(TRAIN_PATH)

# Выделяем файлы для теста
test_count = 0
for class_name in CLASS_LIST:
  wot_path = f'{WOT_PATH}/{class_name}'
  #train_path = f'{TRAIN_PATH}/{class_name}'
  test_path = f'{TEST_PATH}/{class_name}'
  wot_files = os.listdir(wot_path)
  wot_file_count = len(wot_files)
  os.mkdir(test_path)
  #os.mkdir(train_path)
  #train_file_count = int(wot_file_count*TRAIN_SPLIT)
  test_file_count =int(wot_file_count*TEST_SPLIT)
  test_files = wot_files[:test_file_count]
  for f in test_files:
    os.rename(f'{wot_path}/{f}', f'{test_path}/{f}')
  #train_files = wot_files[test_file_count+train_file_count: ]
  print(f'Размер класса {class_name}: {wot_file_count} машин, для теста выделено : {test_file_count}')

# Выделяем файлы для обучения/тренировки
train_count = 0
for class_name in CLASS_LIST:
  wot_path = f'{WOT_PATH}/{class_name}'
  train_path = f'{TRAIN_PATH}/{class_name}'
  #test_path = f'{TEST_PATH}/{class_name}'
  wot_files = os.listdir(wot_path)
  wot_file_count = len(wot_files)
  #os.mkdir(test_path)
  os.mkdir(train_path)
  train_file_count = int(wot_file_count*TRAIN_SPLIT)
  #test_file_count =int(wot_file_count*TEST_SPLIT)
  train_files = wot_files[:train_file_count]
  for f in train_files:
    os.rename(f'{wot_path}/{f}', f'{train_path}/{f}')
  #train_files = wot_files[test_file_count+train_file_count: ]
  print(f'Размер класса {class_name}: {wot_file_count} машин, для теста выделено : {train_file_count}')

#!rm -rf WOT

# Визуально проверяем соотвтетсвуют ли файлы названию танка
# for my_class in CLASS_LIST:
#   print(my_class, ' : ', os.listdir(f'{TRAIN_PATH}/{my_class}/'))

# Визуализируем картинки для каждого танка
fig, axs = plt.subplots(1, CLASS_COUNT, figsize=(25,5))

for i in range(CLASS_COUNT):
  tank_path = f'{TRAIN_PATH}/{CLASS_LIST[i]}/'
  img_path = tank_path+random.choice(os.listdir(tank_path))
  axs[i].set_title(CLASS_LIST[i])
  axs[i].imshow(Image.open(img_path))
  axs[i].axis('off')
plt.show()

# Посчитаем количество файлов для обучения
data_files = []
data_labels = []

for class_label in range(CLASS_COUNT):
  class_name = CLASS_LIST[class_label]
  class_path = TRAIN_PATH + '/'+ class_name
  class_files = os.listdir(class_path)
  print(f' Размер класса {class_name} составляет {len(class_files)} танков')
  data_files += [f'{class_path}/{file_name}' for file_name in class_files]
  data_labels += [class_label]*len(class_files)
print('Общий размер базы для обучения:', len(data_labels))

# Посчитаем количество файлов для теста
data_files_2 = []
data_labels_2 = []

for class_label in range(CLASS_COUNT):
  class_name = CLASS_LIST[class_label]
  class_path = TEST_PATH + '/'+ class_name
  class_files = os.listdir(class_path)
  print(f' Размер класса {class_name} составляет {len(class_files)} танков')
  data_files_2 += [f'{class_path}/{file_name}' for file_name in class_files]
  data_labels_2 += [class_label]*len(class_files)
print('Общий размер базы для теста:', len(data_labels_2))

#  Файлы для валидации
n = 0
for class_label in range(CLASS_COUNT):
  class_name = CLASS_LIST[class_label]
  class_path = WOT_PATH + '/'+ class_name
  class_files = os.listdir(class_path)
  print(f' Размер класса {class_name} составляет {len(class_files)} танков')
  n += len(class_files)
print('Общий размер базы для валидации:', n)

# Собираем массив изображений для тренировки
import numpy as np
data_images = []

for file_name in data_files:
  img = Image.open(file_name).resize((IMG_WIDTH, IMG_HEIGHT))
#---------------------------------------
  image = np.array(img, dtype='float64')/255
  image = np.expand_dims(image, axis = 0)
#------------------------------------
  img_np = np.array(img)
  data_images.append(img_np)

x_train = np.array(data_images)
y_train = np.array(data_labels)

print(f'В массиве собрано {len(data_images)} форма: {img_np.shape}')
print(f'Общий img массив формы: {x_train.shape}')
print(f'Общий массив меток: {y_train.shape}')

import numpy as np

# Собираем массив изображений для теста
data_images = []

for file_name in data_files_2:
  img = Image.open(file_name).resize((IMG_WIDTH, IMG_HEIGHT))
  img_np = np.array(img)
  data_images.append(img_np)

x_test = np.array(data_images)
y_test = np.array(data_labels_2)

print(f'В массиве собрано {len(data_images)} форма: {img_np.shape}')
print(f'Общий img массив формы: {x_test.shape}')
print(f'Общий массив меток: {y_test.shape}')

# Собираем массив изображений для валидации
data_images = []

for file_name in data_files_2:
  img = Image.open(file_name).resize((IMG_WIDTH, IMG_HEIGHT))
  img_np = np.array(img)
  data_images.append(img_np)

x_val = np.array(data_images)
y_val = np.array(data_labels_2)

print(f'В массиве собрано {len(data_images)} форма: {img_np.shape}')
print(f'Общий img массив формы: {x_test.shape}')
print(f'Общий массив меток: {y_test.shape}')

"""# ОБУЧЕНИЕ"""



# ПАРАМЕТРЫ ДЛЯ ОБУЧЕНИЯ
OPTIMIZER = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)
BATCH_SIZE = 48
EPOCHS = 20

#ПАРАМЕТРЫ АУГУМЕНТАЦИИ
ROTATION_RANGE = 8
WIDTH_SHIFT_RANGE = 0.15
HEIGHT_SHIFT_RANGE = 0.15
ZOOM_RANGE = 0.15
BRITNESS_RANGE = (0.7,1.3)
HORIZONTAL_FLIP = True

type(BRITNESS_RANGE)

"""# НЕЙРОСЕТЬ

"""

model = Sequential()

# ОБЯЗАТЕЛЬНО - входной слой
model.add(Conv2D(128, (3,3), name='Conv_enter', activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH, IMG_CHANNELS)))

model.add(MaxPooling2D(pool_size=(2,2), name='MaxPool_1'))

# ОБЯЗАТЕЛЬНО - выходные слoи
model.add(Flatten(name='Flatten_exit'))
model.add(Dense(128,activation='relu', name='Dense_last'))
model.add(Dense(CLASS_COUNT, activation='softmax', name='Dense_answer'))

model.summary()



plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

# ФУНКЦИЯ КОМПИЛЯЦИИ И ОБУЧЕНИЯ
def compile_train_model(model,
                        train_data,
                        val_data,
                        optimizer = OPTIMIZER,
                        epochs = EPOCHS,
                        batch_size = BATCH_SIZE,
                        figsize = (20,5)):
  # Компиляция модели
  model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])
  # Обучение нейронной сети
  store_learning = model.fit(train_data,
      epochs=epochs,
      batch_size = batch_size, # размер пакета, который обрабатывается
      validation_data = val_data
  )

  # Создание полотна рисунка
  plt.figure(1, figsize=(18, 5))
  # График ошибки нейронной сети
  plt.subplot(1, 2, 1)
  plt.plot(store_learning.history['loss'], label='Ошибка об.выборка')
  plt.plot(store_learning.history['val_loss'], label='Ошибка вал.выборка')
  plt.xlabel('Эпоха обучения')
  plt.ylabel('Значение ошибки')
  plt.legend()
  # График точности нейроннной сети
  plt.subplot(1, 2, 2)
  plt.plot(store_learning.history['accuracy'], label = 'Доля верных ответов на обучающей выборке')
  plt.plot(store_learning.history['val_accuracy'], label = 'Доля верных ответов на проверочной выборке')
  plt.xlabel('Эпоха обучения')
  plt.ylabel('Доля верных ответов')
  plt.legend()

  plt.show()

# ФУНКЦИИ ВЫВОДА РЕЗУЛЬТАТОВ
def eva_model(model,
              x,
              y_true,
              class_labels=[],
              cm_round = 3,
              title = '',
              figsize=(10,10)):
  y_pred = model.predict(x)
  cm = confusion_matrix(np.argmax(y_true, axis=1),
                        np.argmax(y_pred, axis=1),
                        normalize = 'true')
  cm = np.around(cm, cm_round)
  # ОТРИСОВКА МАТРИЦЫ ОШИБОК
  fig, ax = plt.subplots(figsize=figsize)
  ax.set_title(f'Нейросеть {title}: матрица ошибок нормализованная', fontsize=18)
  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)
  disp.plot(ax=ax)
  ax.images[-1].colorbar.remove()
  fig.autofmt_xdate(rotation=45)
  plt.xlabel('Предсказанные классы', fontsize=16)
  plt.ylabel('Верные классы', fontsize=16)
  plt.show()

  print('-'*100)
  print(f'Нейросеть: {title}')
  for cls in range(len(class_labels)):
    cls_pred = np.argmax(cm[cls])
    msg = 'ВЕРНО ' if cls_pred == cls else 'НЕВЕРНО'
    print('Класс: {:<20} {:3.0f}% сеть отнесла к классу {:<20} - {}'.format(class_labels[cls],
                                                                            100.*cm[cls,cls_pred],
                                                                            class_labels[cls_pred],
                                                                            msg))
  #Средняя точность распознования
  print('\n Средняя точность распознования: {:3.0f}%'.format(100.*cm.diagonal().mean()))

# Совместная функция
def union_function(model,
                   train_data,
                   val_data,
                   test_data,
                   class_labels = CLASS_LIST,
                   title = '',
                   optimizer = OPTIMIZER,
                   epochs = EPOCHS,
                   batch_size = BATCH_SIZE,
                   graph_size = (20,5),
                   cm_size = (10,10)):
  compile_train_model(model,
                      train_data,
                      val_data,
                      optimizer = optimizer,
                      epochs = epochs,
                      batch_size = batch_size,
                      figsize = graph_size)
  eva_model(model,
            test_data[0][0],
            test_data[0][1],
            class_labels= class_labels,
            title = title,
            figsize = cm_size)

x_train.shape

y_train.shape

model.load_weights('/content/weights.h5')

# Компиляция модели
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), optimizer=OPTIMIZER, metrics=['accuracy'])
  # Обучение нейронной сети
store_learning = model.fit(x_train, y_train,
      epochs=EPOCHS,
      batch_size = BATCH_SIZE, # размер пакета, который обрабатывается
      validation_data=(x_val, y_val)
  )

CLASS_LIST

# Для сохранения результатов
# веса
model.save_weights('weights.h5')

# сохранение архитектуры модели и весов
model.save('All_model_w.h5')

from google.colab import drive
drive.mount('/content/drive')

def predict(img_path='', model_path='/content/drive/MyDrive/RealTanks_model.h5'):
  classes = CLASS_LIST
  model = load_model(model_path)
  img = Image.open(img_path).resize((IMG_WIDTH, IMG_HEIGHT))
  image = np.array(img, dtype='float64')/255
  image = np.expand_dims(image, axis = 0)
  result  = model.predict(image)
  result_ = np.round(result, 2)
  cls_image = np.argmax(result_)
  print(img_path)
  print('На изображении танк: ', classes[cls_image], ' {:.0%}'.format(float(result_[0][cls_image])))
  plt.imshow(Image.open(img_path))

result_

predict(img_path='/content/TEST/PT91_Twardy/PT-91 Twardy_0029.jpg')

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
model = keras.models.load_model('/content/drive/MyDrive/RealTanks_model.h5')

y_pred = model.predict(x_test)
Y_pred = np.argmax(y_pred, axis=1)

cm = confusion_matrix(y_test, Y_pred)

display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASS_LIST)

display.plot(xticks_rotation=45)
